{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d423094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading QuickDraw files: 100%|██████████| 2/2 [00:00<00:00, 7717.21it/s]\n",
      "Loading QuickDraw files: 100%|██████████| 2/2 [00:05<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized data from sketch_tokenized_dataset_test_gpt2.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1607' max='151835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1607/151835 08:23 < 13:05:34, 3.19 it/s, Epoch 0.05/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.248100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.251300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.234400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     11\u001b[39m training_args = TrainingArguments(\n\u001b[32m     12\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     num_train_epochs=\u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     fp16=\u001b[38;5;28;01mTrue\u001b[39;00m,               \u001b[38;5;66;03m# only helps if on GPU\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m trainer = Trainer(\n\u001b[32m     23\u001b[39m     model=model,\n\u001b[32m     24\u001b[39m     args=training_args,\n\u001b[32m     25\u001b[39m     train_dataset=dataset,\n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\trainer.py:2677\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2672\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2675\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2677\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2678\u001b[39m ):\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2680\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2681\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from finetuning_dataset import QuickDrawFineTuningDataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset = QuickDrawFineTuningDataset(labels=[\"apple\", \"cat\"], tokenizer=tokenizer, max_length=1024)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=200,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7722194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat sketch M25,13C14,0 4,8 3,19C0,32 5,52 21,57C25,57 27,62 29,62M27,12C22,12 19,9 13,13C9,16 10,19 7,22C7,26 14,27 17,28C20,30 31,25 32,27C33,25 33,24 34,23C37,23 37,21 38,20M35,13C35,10 33,5 33,3C31,0 33,8 33,12M26,15C27,14 29,14 29,15M43,15C39,15 35,16 36,17M31,16C34,16 36,17 41,16M31,17C32,19 37,17 39,17M30,17C34,17 38,16 40,15M31,17C32,19 32,20 32,25C31,24 32,24 31,24M29,26C27,29 26,30 25,29M25,26C26,27 28,28 31,28M25,27C25,28 26,30 27,30M29,25C29,25 28,28 28,28M28,26C32,28 37,29 37,29\n",
      "<svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
      "<path d=\" M25,13C14,0 4,8 3,19C0,32 5,52 21,57C25,57 27,62 29,62M27,12C22,12 19,9 13,13C9,16 10,19 7,22C7,26 14,27 17,28C20,30 31,25 32,27C33,25 33,24 34,23C37,23 37,21 38,20M35,13C35,10 33,5 33,3C31,0 33,8 33,12M26,15C27,14 29,14 29,15M43,15C39,15 35,16 36,17M31,16C34,16 36,17 41,16M31,17C32,19 37,17 39,17M30,17C34,17 38,16 40,15M31,17C32,19 32,20 32,25C31,24 32,24 31,24M29,26C27,29 26,30 25,29M25,26C26,27 28,28 31,28M25,27C25,28 26,30 27,30M29,25C29,25 28,28 28,28M28,26C32,28 37,29 37,29\" stroke=\"black\" fill=\"none\"/>\n",
      "</g></svg>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>char len: 583</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\" M25,13C14,0 4,8 3,19C0,32 5,52 21,57C25,57 27,62 29,62M27,12C22,12 19,9 13,13C9,16 10,19 7,22C7,26 14,27 17,28C20,30 31,25 32,27C33,25 33,24 34,23C37,23 37,21 38,20M35,13C35,10 33,5 33,3C31,0 33,8 33,12M26,15C27,14 29,14 29,15M43,15C39,15 35,16 36,17M31,16C34,16 36,17 41,16M31,17C32,19 37,17 39,17M30,17C34,17 38,16 40,15M31,17C32,19 32,20 32,25C31,24 32,24 31,24M29,26C27,29 26,30 25,29M25,26C26,27 28,28 31,28M25,27C25,28 26,30 27,30M29,25C29,25 28,28 28,28M28,26C32,28 37,29 37,29\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"cat sketch\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Move to GPU if available\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=1024,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,          # random sampling\n",
    "    top_k=50,                # limits sampling pool\n",
    "    top_p=0.95,              # nucleus sampling\n",
    "    temperature=0.8,         # controls randomness\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Decode and print\n",
    "out = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(out)\n",
    "\n",
    "out = out.split(prompt, 1)[-1]  # remove prompt\n",
    "\n",
    "out_svg=f\"\"\"<svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
    "<path d=\"{out}\" stroke=\"black\" fill=\"none\"/>\n",
    "</g></svg>\"\"\"\n",
    "\n",
    "print(out_svg)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(f\"\"\"<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>char len: {len(out_svg)}</b><br>{out_svg}</div>\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
