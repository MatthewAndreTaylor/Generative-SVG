{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632aa9ac",
   "metadata": {},
   "source": [
    "# Initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651fca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import QuickDrawDataset\n",
    "from utils import AbsolutePenPositionTokenizer\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c0017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dd2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading QuickDraw files: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized data from sketch_tokenized_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "labels = [\"cat\"]\n",
    "training_data = QuickDrawDataset(labels=labels, download=True)\n",
    "tokenizer = AbsolutePenPositionTokenizer(bins=32)\n",
    "\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        svg_list,\n",
    "        tokenizer,\n",
    "        max_len=200,\n",
    "        cache_file=\"sketch_tokenized_dataset.pkl\",\n",
    "    ):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = tokenizer.vocab[\"PAD\"]\n",
    "\n",
    "        # Try to load from cache\n",
    "        try:\n",
    "            with open(cache_file, \"rb\") as f:\n",
    "                self.data = pickle.load(f)\n",
    "            print(f\"Loaded tokenized data from {cache_file}\")\n",
    "        except FileNotFoundError:\n",
    "            for svg in tqdm(svg_list, desc=\"Tokenizing SVGs\"):\n",
    "                tokens = tokenizer.encode(svg)[:max_len]\n",
    "                tokens = tokens + [self.pad_id] * (max_len - len(tokens))\n",
    "                self.data.append(tokens)\n",
    "\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(self.data, f)\n",
    "            print(f\"Saved tokenized data to {cache_file}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        input_ids = torch.tensor(seq[:-1])\n",
    "        target_ids = torch.tensor(seq[1:])\n",
    "        return input_ids, target_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = SketchDataset(training_data, tokenizer, max_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d81d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(sz: int):\n",
    "    \"\"\"Causal mask to stop attention to future positions\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "\n",
    "\n",
    "class SketchTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=6, max_len=200):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model\n",
    "        )  # , activation='gelu'\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) input tokens\n",
    "        Returns: (batch, seq_len, vocab_size) logits\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0)\n",
    "        x = self.embed(x) + self.pos_embed(positions)  # (batch, seq_len, d_model)\n",
    "        x = x.transpose(0, 1)  # -> (seq_len, batch, d_model)\n",
    "        mask = generate_square_subsequent_mask(seq_len).to(\n",
    "            x.device\n",
    "        )  # causal mask (seq_len, seq_len)\n",
    "        x = self.transformer(x, mask=mask)  # (seq_len, batch, d_model)\n",
    "        x = x.transpose(0, 1)  # back to (batch, seq_len, d_model)\n",
    "        logits = self.fc_out(x)  # (batch, seq_len, vocab_size)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, vocab_size, epochs=10, lr=1e-4, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore pad token\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for input_ids, target_ids in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "\n",
    "            # Transformer expects shape (seq_len, batch, d_model)\n",
    "            logits = model(input_ids)  # (seq_len, batch, vocab_size)\n",
    "            loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, pin_memory=True)\n",
    "model = SketchTransformer(\n",
    "    vocab_size=len(tokenizer.vocab), d_model=256, nhead=8, num_layers=6\n",
    ")\n",
    "# model = torch.load(\"sketch_transformer_cat_checkpoint0.pth\", weights_only=False)\n",
    "\n",
    "# train_model(\n",
    "#     model,\n",
    "#     dataloader,\n",
    "#     vocab_size=len(tokenizer.vocab),\n",
    "#     epochs=40,\n",
    "#     lr=1e-4,\n",
    "#     device=device,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a32060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"sketch_transformer_cat_checkpoint1.pth\")\n",
    "# model = torch.load(\"sketch_transformer_cat_checkpoint1.pth\", map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1502569",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     61\u001b[39m         tokens_tensor = torch.cat([tokens_tensor, next_token_tensor], dim=\u001b[32m1\u001b[39m)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m start_token = \u001b[43mtokenizer\u001b[49m.vocab[\u001b[33m\"\u001b[39m\u001b[33mSTART\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     67\u001b[39m eos_token = tokenizer.vocab.get(\u001b[33m\"\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     69\u001b[39m generations_inline = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def top_p_filtering(logits, p=0.9):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    sorted_indices_to_remove = cumulative_probs > p\n",
    "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "    sorted_indices_to_remove[..., 0] = False\n",
    "    indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "    logits[:, indices_to_remove] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "\n",
    "def top_k_filtering(logits, k):\n",
    "    if k <= 0:\n",
    "        return logits\n",
    "    top_k = min(k, logits.size(-1))\n",
    "    values, _ = torch.topk(logits, top_k)\n",
    "    min_values = values[:, -1].unsqueeze(-1)\n",
    "    logits[logits < min_values] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "\n",
    "def sample_sequence_feat(\n",
    "    model,\n",
    "    start_token,\n",
    "    max_len=200,\n",
    "    temperature=1.0,\n",
    "    top_k=60,\n",
    "    top_p=0.9,\n",
    "    greedy=False,\n",
    "    eos_id=None,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "    tokens = [start_token]\n",
    "    tokens_tensor = torch.tensor([tokens], device=device)\n",
    "\n",
    "    for _ in range(max_len - 1):\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens_tensor)\n",
    "            next_logits = logits[:, -1, :] / temperature\n",
    "\n",
    "            # top-k / top-p filtering\n",
    "            next_logits = top_k_filtering(next_logits, top_k)\n",
    "            next_logits = top_p_filtering(next_logits, top_p)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            if greedy:\n",
    "                next_token = torch.argmax(probs, dim=-1).item()\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        tokens.append(next_token)\n",
    "\n",
    "        if eos_id is not None and next_token == eos_id:\n",
    "            break\n",
    "\n",
    "        next_token_tensor = torch.tensor([[next_token]], device=device)\n",
    "        tokens_tensor = torch.cat([tokens_tensor, next_token_tensor], dim=1)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "start_token = tokenizer.vocab[\"START\"]\n",
    "eos_token = tokenizer.vocab.get(\"END\", None)\n",
    "generations_inline = \"\"\n",
    "\n",
    "for i in range(5):\n",
    "    generated = sample_sequence_feat(\n",
    "        model,\n",
    "        start_token,\n",
    "        max_len=200,\n",
    "        temperature=1.0,\n",
    "        greedy=False,\n",
    "        eos_id=eos_token,\n",
    "        device=device,\n",
    "    )\n",
    "    decoded_sketch = tokenizer.decode(generated, stroke_width=0.3)\n",
    "\n",
    "    # print(\"Generated token sequence:\", generated)\n",
    "    # print(\"Decoded sketch:\", decoded_sketch)\n",
    "    generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{decoded_sketch}</div>'\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(generations_inline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca85197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Input</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 22 12 L 22 12 L 23 13 L 28 15 L 31 13 L 35 10 L 40 5 L 44 1 L 46 0 L 47 4 L 50 10 L 53 15 L 55 20 L 55 27 L 55 32 L 49 37 L 44 42 L 37 45 L 26 46 L 22 46 L 17 43 L 13 41 L 9 34 L 6 28 L 3 25 L 4 19 L 7 13 L 12 0 L 14 1 L 19 12 L 22 13\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 28 24 L 27 23\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 35 24 L 34 24\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 33 30 L 30 32 L 32 34 L 32 33 L 32 30\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 31 32 L 32 37 L 30 38 L 26 38 L 23 35 L 24 33\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 31 32 L 35 36 L 37 38 L 40 36\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 47 25 L 63 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 48 28 L 53 28 L 61 30\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 48 34 L 59 39\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 25 L 0 24\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 14 30 L 9 33\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example generation\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Generated token sequence: [4098, 4096, 1420, 1420, 1485, 1807, 1997, 2250, 2565, 2817, 2944, 3012, 3210, 3407, 3540, 3547, 3552, 3173, 2858, 2413, 1710, 1454, 1131, 873, 610, 412, 217, 275, 461, 768, 897, 1228, 1421, 4096, 1816, 1751, 4096, 2264, 2200, 4096, 2142, 1952, 2082, 2081, 2078, 4096, 2016, 2085, 1958, 1702, 1507, 1569, 4096, 2016, 2276, 2406, 2596, 4096, 3033, 4051, 4096, 3100, 3420, 3934, 4096, 3106, 3815, 4096, 857, 24, 4096, 926, 609, 4099]\n",
    "\n",
    "svg_inline = \"\"\"<svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
    "<path d=\"M 22 12 L 22 12 L 23 13 L 28 15 L 31 13 L 35 10 L 40 5 L 44 1 L 46 0 L 47 4 L 50 10 L 53 15 L 55 20 L 55 27 L 55 32 L 49 37 L 44 42 L 37 45 L 26 46 L 22 46 L 17 43 L 13 41 L 9 34 L 6 28 L 3 25 L 4 19 L 7 13 L 12 0 L 14 1 L 19 12 L 22 13\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 28 24 L 27 23\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 35 24 L 34 24\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 33 30 L 30 32 L 32 34 L 32 33 L 32 30\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 31 32 L 32 37 L 30 38 L 26 38 L 23 35 L 24 33\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 31 32 L 35 36 L 37 38 L 40 36\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 47 25 L 63 19\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 48 28 L 53 28 L 61 30\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 48 34 L 59 39\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 13 25 L 0 24\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 14 30 L 9 33\" stroke=\"black\" fill=\"none\"/>\n",
    "</g></svg>\"\"\"\n",
    "display(\n",
    "    HTML(\n",
    "        f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Input</b><br>{svg_inline}</div>'\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
