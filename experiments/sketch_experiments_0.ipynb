{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632aa9ac",
   "metadata": {},
   "source": [
    "# Experiment 0:\n",
    "\n",
    "- Our base sketch transformer architecture\n",
    "- Single class\n",
    "- AbsolutePenPositionTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b576ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_dir import set_cwd_project_root\n",
    "\n",
    "set_cwd_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d81d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading QuickDrawDataset files: 100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
      "Loading QuickDrawDataset: 1it [00:00, 481.83it/s]\n",
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Tokenizing dataset: 100%|██████████| 1/1 [00:00<00:00, 1453.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found, starting from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial Eval: 100%|██████████| 81/81 [00:00<00:00, 197.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset import QuickDrawDataset\n",
    "from sketch_tokenizers import AbsolutePenPositionTokenizer\n",
    "from models import SketchTransformer\n",
    "from runner import SketchTrainer, sample\n",
    "\n",
    "dataset = QuickDrawDataset(label_names=[\"cat\"], download=True)\n",
    "tokenizer = AbsolutePenPositionTokenizer(bins=32)\n",
    "model = SketchTransformer(\n",
    "    vocab_size=len(tokenizer.vocab), d_model=384, nhead=8, num_layers=8, max_len=200\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"log_dir\": \"logs/sketch_transformer_experiment_0\",\n",
    "    \"splits\": [0.85, 0.1, 0.05],\n",
    "    # \"use_padding_mask\": True,\n",
    "}\n",
    "\n",
    "# use padding mask = True\n",
    "# Attention layers: Ignore padded tokens when computing attention weights\n",
    "# Loss function: Ignore padded positions when computing loss\n",
    "# It is more computationally expensive, but can have better results for variable-length sequences (like sketches)\n",
    "\n",
    "trainer = SketchTrainer(model, dataset, tokenizer, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc5bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.37it/s]\n",
      "Epoch 1/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.9635 | Val Loss: 1.5408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.35it/s]\n",
      "Epoch 2/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.4311 | Val Loss: 1.3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [train]: 100%|██████████| 685/685 [01:11<00:00,  9.56it/s]\n",
      "Epoch 3/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 33.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.3073 | Val Loss: 1.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [train]: 100%|██████████| 685/685 [01:11<00:00,  9.52it/s]\n",
      "Epoch 4/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 33.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.2525 | Val Loss: 1.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [train]: 100%|██████████| 685/685 [01:10<00:00,  9.67it/s]\n",
      "Epoch 5/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 34.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.2183 | Val Loss: 1.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [train]: 100%|██████████| 685/685 [01:11<00:00,  9.53it/s]\n",
      "Epoch 6/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 33.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.1943 | Val Loss: 1.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [train]: 100%|██████████| 685/685 [01:11<00:00,  9.65it/s]\n",
      "Epoch 7/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 34.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.1759 | Val Loss: 1.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [train]: 100%|██████████| 685/685 [01:12<00:00,  9.50it/s]\n",
      "Epoch 8/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.1614 | Val Loss: 1.1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.31it/s]\n",
      "Epoch 9/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.1495 | Val Loss: 1.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.30it/s]\n",
      "Epoch 10/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.1393 | Val Loss: 1.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.31it/s]\n",
      "Epoch 11/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.1301 | Val Loss: 1.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.31it/s]\n",
      "Epoch 12/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.1221 | Val Loss: 1.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.32it/s]\n",
      "Epoch 13/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.1150 | Val Loss: 1.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.36it/s]\n",
      "Epoch 14/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.1087 | Val Loss: 1.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.29it/s]\n",
      "Epoch 15/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.1026 | Val Loss: 1.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [train]: 100%|██████████| 685/685 [01:13<00:00,  9.33it/s]\n",
      "Epoch 16/20 [val]: 100%|██████████| 81/81 [00:02<00:00, 32.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.0972 | Val Loss: 1.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [train]:  12%|█▏        | 84/685 [00:09<01:04,  9.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_mixed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Code\\Generative-SVG\\runner.py:235\u001b[39m, in \u001b[36mtrain_mixed\u001b[39m\u001b[34m(self, num_epochs)\u001b[39m\n\u001b[32m    231\u001b[39m model.train()\n\u001b[32m    232\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_ids, target_ids, class_labels \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [train]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    236\u001b[39m ):\n\u001b[32m    237\u001b[39m     input_ids = input_ids.to(device)\n\u001b[32m    238\u001b[39m     target_ids = target_ids.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# trainer.train()\n",
    "\n",
    "trainer.train_mixed(training_config[\"num_epochs\"])  # mixed precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1502569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\"><g stroke-width=\"0.3\">\n",
       "<path d=\"M 8 5 L 9 4 L 13 3 L 17 3 L 20 4 L 23 6 L 25 8 L 25 10 L 26 12 L 26 15 L 26 18 L 24 22 L 21 24 L 19 24 L 16 25 L 12 24 L 9 22 L 8 20 L 7 16 L 6 14 L 7 10 L 8 8 L 9 6 L 11 5\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 22 4 L 31 0 L 31 2 L 30 4 L 27 9\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 9 5 L 5 3 L 0 1 L 0 1 L 0 2 L 1 6 L 4 11\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 14 L 16 14 L 16 14\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 15 L 15 15 L 14 15\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 16 L 15 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 15 L 17 16 L 19 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 15 L 17 16 L 19 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 17 L 18 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 17 L 16 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 16 L 17 18\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 17 L 16 18\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\"><g stroke-width=\"0.3\">\n",
       "<path d=\"M 7 8 L 6 9 L 4 10 L 3 12 L 2 14 L 1 18 L 2 23 L 4 26 L 7 28 L 11 30 L 15 31 L 18 31 L 22 29 L 24 27 L 25 26 L 27 23 L 27 20 L 27 17 L 26 14 L 25 12 L 22 9 L 18 7 L 13 7 L 9 7\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 3 12 L 3 11 L 1 8 L 0 2 L 0 0 L 2 0 L 3 0 L 5 2 L 8 6\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 7 L 22 5 L 28 2 L 30 1 L 31 2 L 30 5 L 27 10\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 9 13 L 9 15 L 10 14\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 14 L 19 15 L 19 15\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 19 L 14 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 20 L 14 22 L 14 23 L 12 23\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\"><g stroke-width=\"0.3\">\n",
       "<path d=\"M 8 5 L 8 4 L 9 0 L 10 0 L 12 5\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 5 L 15 4 L 19 4 L 21 5\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 5 L 23 2 L 25 1 L 26 5\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 7 7 L 5 10 L 4 13 L 4 17 L 6 19 L 7 21 L 10 23 L 12 23 L 15 23 L 20 22 L 24 20 L 26 18 L 27 15 L 27 13 L 27 8 L 27 6\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 9 L 12 10 L 12 11 L 13 10 L 12 9\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 9 L 19 10 L 19 11 L 19 10 L 19 10 L 20 10 L 19 9\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 16 L 15 16 L 16 16 L 17 16 L 18 16 L 17 16 L 16 17 L 14 17 L 13 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 17 L 16 19 L 15 20 L 13 20 L 11 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 17 L 18 19 L 20 20 L 22 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 16 L 16 19 L 16 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 20 16 L 24 14 L 29 13\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 17 L 26 16 L 31 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 22 19 L 28 21\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 16 L 6 16 L 2 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 18 L 8 19 L 5 20 L 2 22\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 11 19 L 8 20 L 5 21 L 0 23\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\"><g stroke-width=\"0.3\">\n",
       "<path d=\"M 8 8 L 7 7 L 6 6 L 5 4 L 5 1 L 6 0 L 8 1 L 10 5 L 12 5 L 14 4 L 16 4 L 19 5 L 21 1 L 22 0 L 23 0 L 24 0 L 24 1 L 24 6\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 8 8 L 7 9 L 6 11 L 7 14 L 8 17 L 10 18 L 13 19 L 16 20 L 19 20 L 21 19 L 22 18 L 24 15 L 24 12 L 23 9 L 21 7\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 11 11 L 11 12\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 11 L 17 12\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 16 L 14 16 L 15 15\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 16 L 12 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 16 L 13 17 L 13 17 L 15 16 L 14 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 16 L 13 17 L 13 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 14 17 L 14 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 17 L 14 17 L 15 16\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 15 L 27 12\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 17 17 L 25 16 L 31 15\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 17 L 24 18 L 27 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 9 14 L 0 14\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 11 15 L 8 15 L 4 16 L 1 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 16 L 7 17 L 3 20\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\"><g stroke-width=\"0.3\">\n",
       "<path d=\"M 6 7 L 6 8 L 7 10 L 8 11 L 10 12 L 13 12 L 15 12 L 17 12 L 18 11 L 18 9 L 17 7 L 16 6 L 13 6 L 8 6\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 8 6 L 8 4 L 9 0 L 11 5\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 14 6 L 14 3 L 15 1 L 16 0 L 17 0 L 18 3 L 18 7\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 7 L 10 7\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 8 L 13 8\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 10 L 11 11 L 11 11 L 11 10\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 10 L 0 8\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 10 10 L 1 11\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 11 11 L 2 13\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 11 11 L 10 11\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 10 L 15 9 L 18 8\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 11 L 19 10\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 11 L 16 11 L 18 12\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 12 10 L 12 10\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generations_inline = \"\"\n",
    "\n",
    "for i in range(5):\n",
    "    generated = sample(\n",
    "        model=trainer.model,\n",
    "        start_tokens=[trainer.tokenizer.vocab[\"START\"]],\n",
    "        temperature=1.0,\n",
    "        greedy=False,\n",
    "        eos_id=trainer.tokenizer.vocab[\"END\"],\n",
    "    )\n",
    "    decoded_sketch = tokenizer.decode(generated, stroke_width=0.3)\n",
    "    generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{decoded_sketch}</div>'\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(generations_inline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca85197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 22 12 L 22 12 L 23 13 L 28 15 L 31 13 L 35 10 L 40 5 L 44 1 L 46 0 L 47 4 L 50 10 L 53 15 L 55 20 L 55 27 L 55 32 L 49 37 L 44 42 L 37 45 L 26 46 L 22 46 L 17 43 L 13 41 L 9 34 L 6 28 L 3 25 L 4 19 L 7 13 L 12 0 L 14 1 L 19 12 L 22 13\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 28 24 L 27 23\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 35 24 L 34 24\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 33 30 L 30 32 L 32 34 L 32 33 L 32 30\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 31 32 L 32 37 L 30 38 L 26 38 L 23 35 L 24 33\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 31 32 L 35 36 L 37 38 L 40 36\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 47 25 L 63 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 48 28 L 53 28 L 61 30\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 48 34 L 59 39\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 13 25 L 0 24\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 14 30 L 9 33\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example generation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Generated token sequence: [4098, 4096, 1420, 1420, 1485, 1807, 1997, 2250, 2565, 2817, 2944, 3012, 3210, 3407, 3540, 3547, 3552, 3173, 2858, 2413, 1710, 1454, 1131, 873, 610, 412, 217, 275, 461, 768, 897, 1228, 1421, 4096, 1816, 1751, 4096, 2264, 2200, 4096, 2142, 1952, 2082, 2081, 2078, 4096, 2016, 2085, 1958, 1702, 1507, 1569, 4096, 2016, 2276, 2406, 2596, 4096, 3033, 4051, 4096, 3100, 3420, 3934, 4096, 3106, 3815, 4096, 857, 24, 4096, 926, 609, 4099]\n",
    "svg_inline = \"\"\"<svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
    "<path d=\"M 22 12 L 22 12 L 23 13 L 28 15 L 31 13 L 35 10 L 40 5 L 44 1 L 46 0 L 47 4 L 50 10 L 53 15 L 55 20 L 55 27 L 55 32 L 49 37 L 44 42 L 37 45 L 26 46 L 22 46 L 17 43 L 13 41 L 9 34 L 6 28 L 3 25 L 4 19 L 7 13 L 12 0 L 14 1 L 19 12 L 22 13\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 28 24 L 27 23\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 35 24 L 34 24\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 33 30 L 30 32 L 32 34 L 32 33 L 32 30\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 31 32 L 32 37 L 30 38 L 26 38 L 23 35 L 24 33\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 31 32 L 35 36 L 37 38 L 40 36\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 47 25 L 63 19\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 48 28 L 53 28 L 61 30\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 48 34 L 59 39\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 13 25 L 0 24\" stroke=\"black\" fill=\"none\"/>\n",
    "<path d=\"M 14 30 L 9 33\" stroke=\"black\" fill=\"none\"/>\n",
    "</g></svg>\"\"\"\n",
    "display(\n",
    "    HTML(\n",
    "        f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><br>{svg_inline}</div>'\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
