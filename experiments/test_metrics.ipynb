{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486bb518",
   "metadata": {},
   "source": [
    "# Test Experiments\n",
    "\n",
    "Frechet Inception Distance (FID) and Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69440ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_dir import set_cwd_project_root\n",
    "\n",
    "set_cwd_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "407a3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner import SketchTrainer, sample, device\n",
    "from utils import top_k_filtering, top_p_filtering\n",
    "from prepare_data import add_svg_properties, clean_svg, stroke_to_bezier_single\n",
    "from main import load_config\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import torchvision\n",
    "from raster_dataset import svg_rasterize\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def to_3ch_tensor(img_pil):\n",
    "    arr = np.array(img_pil, dtype=np.float32) / 255.0  # H×W in [0,1]\n",
    "    t = torch.from_numpy(arr).unsqueeze(0)  # 1×H×W\n",
    "    return t.repeat(3, 1, 1)  # 3×H×W\n",
    "\n",
    "\n",
    "def test_next_token_accuracy(sketch_trainer: SketchTrainer):\n",
    "    model = sketch_trainer.model\n",
    "    test_loader = sketch_trainer.test_loader\n",
    "    use_padding_mask = sketch_trainer.use_padding_mask\n",
    "    model.eval()\n",
    "    test_token_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, target_ids, class_labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            input_ids = input_ids.to(device)\n",
    "            target_ids = target_ids.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "\n",
    "            if use_padding_mask:\n",
    "                mask = input_ids == sketch_trainer.tokenizer.pad_token_id\n",
    "                logits = model(input_ids, class_labels, src_key_padding_mask=mask)\n",
    "            else:\n",
    "                logits = model(input_ids, class_labels)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            mask = target_ids != sketch_trainer.tokenizer.pad_token_id\n",
    "            correct = (preds[mask] == target_ids[mask]).float().sum()\n",
    "            total = mask.sum()\n",
    "\n",
    "            acc = (correct / total) if total > 0 else torch.tensor(0.0, device=device)\n",
    "            test_token_accuracy += acc.item()\n",
    "\n",
    "    avg_acc = test_token_accuracy / len(test_loader)\n",
    "    print(f\"Test Next Token Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "\n",
    "def generate_autoregressive(\n",
    "    model,\n",
    "    class_labels,\n",
    "    tokenizer,\n",
    "    max_len,\n",
    "    device,\n",
    "    temperature=0.8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Autoregressively generate token sequences using SketchTransformer.\n",
    "\n",
    "    Returns:\n",
    "        seq: (batch, T) long tensor, starting with START, possibly ending with END.\n",
    "    \"\"\"\n",
    "    start_id = tokenizer.vocab[\"START\"]\n",
    "    end_id = tokenizer.vocab[\"END\"]\n",
    "\n",
    "    model.eval()\n",
    "    B = class_labels.size(0)\n",
    "    seq = torch.full(\n",
    "        (B, 1),\n",
    "        start_id,\n",
    "        dtype=torch.long,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    finished = torch.zeros(B, dtype=torch.bool, device=device)\n",
    "\n",
    "    for _ in range(max_len - 1):\n",
    "        logits = model(seq, class_labels)\n",
    "        next_logits = logits[:, -1, :]\n",
    "\n",
    "        # Only use the logits at the last time step\n",
    "        next_logits = logits[:, -1, :] / temperature  # (B, vocab_size)\n",
    "        probs = torch.softmax(next_logits, dim=-1)\n",
    "        next_tokens = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "\n",
    "        # Append next token\n",
    "        seq = torch.cat([seq, next_tokens.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # Track which sequences have produced END\n",
    "        finished |= next_tokens == end_id\n",
    "        if finished.all():\n",
    "            break\n",
    "\n",
    "    return seq\n",
    "\n",
    "\n",
    "def trim_ids_for_decode(ids, end_id, pad_id):\n",
    "    \"\"\"\n",
    "    Trim a token list at the first END (inclusive) or PAD (exclusive), whichever comes first.\n",
    "    \"\"\"\n",
    "    cut = len(ids)\n",
    "    if end_id in ids:\n",
    "        cut = min(cut, ids.index(end_id) + 1)  # keep END\n",
    "    if pad_id in ids:\n",
    "        cut = min(cut, ids.index(pad_id))  # drop PAD\n",
    "    return ids[:cut]\n",
    "\n",
    "\n",
    "def test_fid_inception_score(\n",
    "    sketch_trainer: SketchTrainer,\n",
    "    num_samples=None,\n",
    "    bezier_postprocess=True,\n",
    "    canvas_size=128,\n",
    "):\n",
    "    model = sketch_trainer.model\n",
    "    test_loader = sketch_trainer.test_loader\n",
    "    tokenizer = sketch_trainer.tokenizer\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    start_id = tokenizer.vocab[\"START\"]\n",
    "    end_id = tokenizer.vocab[\"END\"]\n",
    "\n",
    "    def trim_ids_for_decode(ids):\n",
    "        cut = len(ids)\n",
    "        if end_id in ids:\n",
    "            cut = min(cut, ids.index(end_id) + 1)\n",
    "        if pad_id in ids:\n",
    "            cut = min(cut, ids.index(pad_id))\n",
    "        return ids[:cut]\n",
    "\n",
    "    # torchmetrics FID & IS\n",
    "    fid = FrechetInceptionDistance(normalize=False).to(device)\n",
    "    inception = InceptionScore(splits=10, normalize=False).to(device)\n",
    "\n",
    "    all_real_images = []  # will hold all images across every batch\n",
    "    all_fake_images = []\n",
    "\n",
    "    if num_samples is None:\n",
    "        num_samples = len(test_loader)\n",
    "\n",
    "    it = list(test_loader)[:num_samples]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, target_ids, class_labels in tqdm(it, desc=\"FID/IS\"):\n",
    "            class_labels = class_labels.to(device)\n",
    "            max_len = model.max_len\n",
    "            fake_seqs = generate_autoregressive(\n",
    "                model=model,\n",
    "                class_labels=class_labels,\n",
    "                tokenizer=tokenizer,\n",
    "                max_len=max_len,\n",
    "                device=device,\n",
    "            )\n",
    "            fake_cpu = fake_seqs.cpu()\n",
    "\n",
    "            real_batch = []\n",
    "            fake_batch = []\n",
    "\n",
    "            B = fake_cpu.size(0)\n",
    "            for b in range(B):\n",
    "                real_ids = [start_id] + [\n",
    "                    t for t in target_ids[b].tolist() if t != pad_id\n",
    "                ]\n",
    "                real_ids = trim_ids_for_decode(real_ids)\n",
    "                real_svg = tokenizer.decode(real_ids)\n",
    "                if bezier_postprocess:\n",
    "                    real_svg = stroke_to_bezier_single(real_svg)\n",
    "                    real_svg = clean_svg(real_svg)\n",
    "                real_svg = add_svg_properties(\n",
    "                    real_svg, width=canvas_size, height=canvas_size\n",
    "                )\n",
    "                real_img = svg_rasterize(real_svg)  # PIL grayscale image\n",
    "                r = to_3ch_tensor(real_img)\n",
    "\n",
    "                fake_ids = [t for t in fake_cpu[b].tolist() if t != pad_id]\n",
    "                fake_ids = trim_ids_for_decode(fake_ids)\n",
    "                fake_svg = tokenizer.decode(fake_ids)\n",
    "                if bezier_postprocess:\n",
    "                    fake_svg = stroke_to_bezier_single(fake_svg)\n",
    "                    fake_svg = clean_svg(fake_svg)\n",
    "                fake_svg = add_svg_properties(\n",
    "                    fake_svg, width=canvas_size, height=canvas_size\n",
    "                )\n",
    "\n",
    "                fake_img = svg_rasterize(fake_svg)\n",
    "                f = to_3ch_tensor(fake_img)\n",
    "\n",
    "                real_batch.append(r.unsqueeze(0))  # 1×3×H×W\n",
    "                fake_batch.append(f.unsqueeze(0))\n",
    "\n",
    "            all_real_images.extend(real_batch)\n",
    "            all_fake_images.extend(fake_batch)\n",
    "\n",
    "            real_images = torch.cat(real_batch, dim=0).to(\n",
    "                device=device, dtype=torch.uint8\n",
    "            )\n",
    "            fake_images = torch.cat(fake_batch, dim=0).to(\n",
    "                device=device, dtype=torch.uint8\n",
    "            )\n",
    "\n",
    "            fid.update(real_images, real=True)\n",
    "            fid.update(fake_images, real=False)\n",
    "            inception.update(fake_images)\n",
    "\n",
    "    all_real_images = torch.cat(all_real_images, dim=0).cpu()\n",
    "    all_fake_images = torch.cat(all_fake_images, dim=0).cpu()\n",
    "\n",
    "    # save one image each\n",
    "    torchvision.utils.save_image(all_real_images, \"real_grid.png\")\n",
    "    torchvision.utils.save_image(all_fake_images, \"fake_grid.png\")\n",
    "\n",
    "    fid_score = fid.compute().item()\n",
    "    is_mean, is_std = inception.compute()\n",
    "    is_mean = is_mean.item()\n",
    "    is_std = is_std.item()\n",
    "\n",
    "    sketch_trainer.writer.add_scalar(\"FID/Test\", fid_score, 0)\n",
    "    sketch_trainer.writer.add_scalar(\"IS/TestMean\", is_mean, 0)\n",
    "    sketch_trainer.writer.add_scalar(\"IS/TestStd\", is_std, 0)\n",
    "\n",
    "    print(f\"Test FID: {fid_score:.4f}\")\n",
    "    print(f\"Test Inception Score: mean={is_mean:.4f}, std={is_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e2adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56c465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading QuickDrawDataset files: 100%|██████████| 5/5 [00:00<00:00, 10974.11it/s]\n",
      "Loading QuickDrawDataset: 5it [00:00, 326.09it/s]\n",
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Tokenizing dataset: 100%|██████████| 5/5 [00:00<00:00, 618.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from checkpoint: logs/sketch_transformer_experiment_5/20251115_192110/model_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial Eval: 100%|██████████| 464/464 [00:02<00:00, 177.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset import QuickDrawDataset\n",
    "from sketch_tokenizers import DeltaPenPositionTokenizer\n",
    "from models import SketchTransformerConditional\n",
    "from runner import SketchTrainer, sample\n",
    "\n",
    "label_names = [\"monkey\", \"fish\", \"sailboat\", \"skull\", \"whale\"]\n",
    "dataset = QuickDrawDataset(label_names=label_names, download=True)\n",
    "tokenizer = DeltaPenPositionTokenizer(bins=16)\n",
    "\n",
    "model = SketchTransformerConditional(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    d_model=384,\n",
    "    nhead=8,\n",
    "    num_layers=8,\n",
    "    max_len=200,\n",
    "    num_classes=len(label_names),\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 15,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"log_dir\": \"logs/sketch_transformer_experiment_5\",\n",
    "    \"splits\": [0.85, 0.1, 0.05],\n",
    "    # \"use_padding_mask\": True,\n",
    "    \"checkpoint_path\": \"logs/sketch_transformer_experiment_5/20251115_192110/model_8.pt\",\n",
    "}\n",
    "\n",
    "trainer = SketchTrainer(model, dataset, tokenizer, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef96c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = load_config(\"configs/example_0.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eff09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_next_token_accuracy(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1e85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "FID/IS: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test FID: 5.2216\n",
      "Test Inception Score: mean=1.0596, std=0.0061\n"
     ]
    }
   ],
   "source": [
    "test_fid_inception_score(trainer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dce68779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "FID/IS: 100%|██████████| 20/20 [01:29<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test FID: 0.8337\n",
      "Test Inception Score: mean=1.0513, std=0.0027\n"
     ]
    }
   ],
   "source": [
    "test_fid_inception_score(trainer, 20, bezier_postprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e1d0734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "FID/IS: 100%|██████████| 20/20 [01:36<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test FID: 0.2979\n",
      "Test Inception Score: mean=1.0254, std=0.0007\n"
     ]
    }
   ],
   "source": [
    "test_fid_inception_score(trainer, 20, canvas_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
