{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632aa9ac",
   "metadata": {},
   "source": [
    "# Initial experiments Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651fca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import QuickDrawDataset\n",
    "from utils import DeltaPenPositionTokenizer\n",
    "from prepare_data import stroke_to_rdp, stroke_to_bezier_single, clean_svg\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c0017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0dd2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading QuickDraw files: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
      "Loading QuickDraw files: 100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized data from sketch_rdp_tokenized_200_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "labels = [\"cat\"]\n",
    "training_data = QuickDrawDataset(labels=labels, download=True)\n",
    "tokenizer = DeltaPenPositionTokenizer(bins=32)\n",
    "\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        svg_list,\n",
    "        tokenizer,\n",
    "        max_len=200,\n",
    "        cache_file=\"sketch_rdp_tokenized_200_dataset.pkl\",\n",
    "    ):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = tokenizer.vocab[\"PAD\"]\n",
    "\n",
    "        # Try to load from cache\n",
    "        try:\n",
    "            with open(cache_file, \"rb\") as f:\n",
    "                self.data = pickle.load(f)\n",
    "            print(f\"Loaded tokenized data from {cache_file}\")\n",
    "        except FileNotFoundError:\n",
    "            for svg in tqdm(svg_list, desc=\"Tokenizing SVGs\"):\n",
    "                # use RDP to reduce number of points in SVG\n",
    "                svg = stroke_to_rdp(svg, epsilon=1.0)  # tuning\n",
    "                tokens = tokenizer.encode(svg)\n",
    "                tokens = tokens[:max_len]\n",
    "                tokens = tokens + [self.pad_id] * (max_len - len(tokens))\n",
    "                self.data.append(tokens)\n",
    "\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(self.data, f)\n",
    "            print(f\"Saved tokenized data to {cache_file}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        input_ids = torch.tensor(seq[:-1])\n",
    "        target_ids = torch.tensor(seq[1:])\n",
    "        return input_ids, target_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = SketchDataset(training_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d81d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(sz: int):\n",
    "    \"\"\"Causal mask to stop attention to future positions\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "\n",
    "\n",
    "class SketchTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=384, nhead=8, num_layers=6, max_len=200):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) input tokens\n",
    "        Returns: (batch, seq_len, vocab_size) logits\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0)\n",
    "        x = self.embed(x) + self.pos_embed(positions)  # (batch, seq_len, d_model)\n",
    "        x = x.transpose(0, 1)  # -> (seq_len, batch, d_model)\n",
    "        mask = generate_square_subsequent_mask(seq_len).to(x.device)  # causal mask (seq_len, seq_len)\n",
    "        x = self.transformer(x, mask=mask)  # (seq_len, batch, d_model)\n",
    "        x = x.transpose(0, 1)  # back to (batch, seq_len, d_model)\n",
    "        logits = self.fc_out(x)  # (batch, seq_len, vocab_size)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, vocab_size, epochs=10, lr=1e-4, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for input_ids, target_ids in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "\n",
    "            # Transformer expects shape (seq_len, batch, d_model)\n",
    "            logits = model(input_ids)  # (seq_len, batch, vocab_size)\n",
    "            loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "model = SketchTransformer(\n",
    "    vocab_size=len(tokenizer.vocab), d_model=512, nhead=8, num_layers=8\n",
    ")\n",
    "\n",
    "# d_model => model capacity (types of drawing features it can learn)\n",
    "# nhead => model can attend to more positions in parallel\n",
    "# num layers => model learns more hierarchical abstractions (patterns, shapes , layouts)\n",
    "\n",
    "# train_model(\n",
    "#     model,\n",
    "#     dataloader,\n",
    "#     vocab_size=len(tokenizer.vocab),\n",
    "#     epochs=20,\n",
    "#     lr=1e-4,\n",
    "#     device=device,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"sketch_transformer_model_cat_v2_deep.pth\")\n",
    "model = torch.load(\"sketch_transformer_model_cat_v2_deep.pth\", map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c1502569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M6,8C4.809017040378642,9.190982959621358 1.5702950877909254,12.111339903392157 1.0571458182308788,13.885708363538242C-0.42728177385010646,19.018564740820658 5.238974418155504,28.31421053042037 10.653377688099079,29C13.712765057751785,29.387502654839118 19.02708622599392,26.43384543533129 21.218807312719527,24.52079512485365C26.221323857912363,20.1543335856036 26.68184981525183,11.769892745684642 20.573000864515862,8.38200057634391C15.9433416298452,5.814448752040396 10.27354755272518,6.391807785650151 6,9M4,11C3.64327494054254,9.929824821627621 1.7278347885083232,1.0584858618222193 3.5713165621197356,1C5.57949502000709,0.9362890105648994 8.870960595599536,6.588700744499419 10,8M19,7C19.119806513075254,5.728826941845279 22.871599636799644,-3.239782095506138 24.845393685088073,-2C25.542481851865162,-1.5621440702443832 24.699724832012542,1.050963087956112 24.553717768247353,1.561987811134271C23.745260586610364,4.391587946863723 22.93072793832154,7.207816185035393 22,10M11,18C11,20.7720638498089 12.338783797849716,19.338783797849715 11,18C9.333333333333332,18 7.666666666666667,18 6,18M10,20C9.000000000000002,20.333333333333343 7.999999999999997,20.666666666666657 7,21M12,20C10.666666666666666,20.66666666666666 9.333333333333337,21.333333333333336 8,22M15,19C15.999999999999996,18.666666666666657 17.000000000000004,18.33333333333334 18,18M15,21C15.666666666666666,21 16.333333333333332,21 17,21M14,21C14.666666666666664,21.333333333333343 15.333333333333334,21.666666666666657 16,22M8,16C8.333333333333332,16 8.666666666666668,16 9,16M16,15C16.333333333333332,15 16.666666666666664,15 17,15\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M7,8C1.3944611065099828,8 -2.0245496377311953,17.63648571094233 4.114026230164825,20C9.691402732725095,22.147437670062367 14.821507441720776,9.718367966155075 7,8M3,9C2.6542265037883275,7.962679511364982 0.6212471173154408,2.337136789133082 2.9372682551001805,2.0627317448998195C5.022121000213691,1.8157158172775367 5,6.980025442871022 5,8M8,7C8.453296490565506,6.0934070188689855 10.265701749817975,-0.032621539863439075 11.831337151716745,1C13.140734415284513,1.863618577453287 10.37101292508937,7.886961224731892 10,9M4,13C4,15.145911184474024 6.145911184474024,13 4,13M4,15C5.469821308656478,16.469821308656478 6.2451010388837425,17.754898961116258 8,16M5,16C3.966529519319777,17.033470480680215 3.4406315586789313,17 2,17M11,14C12.797253864212442,13.64054922715751 14.780587045555977,13.006788350401369 16.62431331102645,13C28.354342806272985,12.9568116200743 23.461936009724283,29.323218406460285 13.447295409796913,24.585471557347685C11.86458818296011,23.836721155154702 10.268157182982918,22.17841043816425 9,21M24,19C24,14.368900195945898 24.42855943226907,9.523813522576974 29,8M9,23C8.66666666666667,24.000000000000004 8.33333333333333,24.999999999999996 8,26M12,23C12,24.333333333333332 12,25.66666666666667 12,27M16,24C16,25 16,26 16,27M22,22C22,23 22,24 22,25M25,20C25,20.66666666666667 25,21.33333333333333 25,22\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M5,8C3.8299146110353037,6.829914611035304 1.3680297881486756,1.4294803189527512 3.705593774323627,0.2944062256763733C5.321990500152962,-0.4904835393939213 7.513796618217296,5.027593236434592 8,6M9,7C9,3.246786090007933 16.981207722046943,5.495301930511736 19,6M19,5C20.761933795506614,-0.2858013865198039 24,-1.4240172025015072 24,5M24,6C32.32302640662283,14.323026406622843 17.208036446081014,20.818821813413575 9.865497822854014,18.93274891142701C3.993412512222343,17.42439035169113 2.520938102008899,11.396309219832586 6,7M16,11C16,12.968937568912713 15.968937568912711,13 14,13M17,11C17,13.453393081542288 17.546606918457712,14 20,14M21,11C22.459639259363787,10.270180370318107 23.36533974973326,10 25,10M21,13C22.333333333333336,12.666666666666666 23.666666666666668,12.333333333333332 25,12M23,15C23.666666666666668,15 24.333333333333332,15 25,15M5,8C3.333333333333332,8 1.6666666666666676,8 0,8M5,10C4.333333333333333,10 3.666666666666667,10 3,10M5,12C4.333333333333332,12.33333333333333 3.6666666666666683,12.666666666666668 3,13M6,13C5.666666666666667,13.333333333333334 5.333333333333334,13.666666666666666 5,14M7,3C7,3.6666666666666665 7,4.333333333333334 7,5\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M7,8C10.207518685360514,4.792481314639487 14.074411815641406,2.658701202122149 18.75943438691854,4.586478128972846C23.567115389214763,6.56472612391444 25.890431291493915,14.033216885925608 23.39060337717255,18.60939662282745C20.813166809718474,23.32764659738026 13.623822494096503,26.00530713698777 9.174831759952875,22.087415879976437C4.642753952075739,18.09635609122308 5.606919553671151,11.658330376115575 8,7C6.830862083264918,5.830862083264918 4.168982855495605,-1.6735991018806864 8.031515095577491,0.03151509557749064C9.39581142657784,0.6337834778032087 10.932438108554223,2.932438108554222 12,4M17,4C17,2.9496985497929606 21.231273216250074,0.220524304848164 22,1.1306856256594116C23.023724867796645,2.3427609657118538 20.478082160294832,6.804794599262927 20,8M13,12C13,12.333333333333334 13,12.666666666666666 13,13M16,12C16.333333333333332,12 16.666666666666664,12 17,12M13,18C13.333333333333332,18 13.66666666666667,18 14,18\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M4,8C4,7.128576021437366 3.431049493957598,0.734726651466233 5.108361815949775,1.108361815949775C6.209510026381348,1.3536516688477123 8.171439182231985,4.1714391822319845 9,5M18,5C18,0.7554721444573049 24,-0.6818409459195571 24,5M6,10C6,5.801915705597676 17.63050171793862,6.815250858969307 20,8M2,12C2,21.41462443054925 15.656196704818935,22.615227348494756 21.6013353506396,17.265776432906932C24.22942489800643,14.90101475568492 24,12.235860881719493 24,9M7,12C8.284340358719529,13.284340358719529 9.42597944355138,12 8,12C5.333333333333332,12 2.666666666666668,12 0,12M8,13C4.874899845806496,13 2.3571042336873576,12.642895766312641 0,15M8,14C5.26253201028074,14 2.2242977747377655,16.55140445052446 1,19M13,12C14.637663862285853,11.18116806885708 16.263972587316186,10.578675804227945 18,10M13,13C15.579935257466051,13 17.547387355623172,13.182462451874391 20,14M13,15C14.333333333333336,15.33333333333333 15.666666666666664,15.666666666666666 17,16M4,8C4,7.666666666666666 4,7.333333333333335 4,7M3,7C3,8.015125165168984 3,8.015125165168982 3,7M10,6C10,7.015125165168984 10,7.015125165168984 10,6\" fill=\"none\" stroke=\"#000000\" /></g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def top_p_filtering(logits, p=0.9):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    sorted_indices_to_remove = cumulative_probs > p\n",
    "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "    sorted_indices_to_remove[..., 0] = False\n",
    "    indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "    logits[:, indices_to_remove] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "def top_k_filtering(logits, k):\n",
    "    if k <= 0:\n",
    "        return logits\n",
    "    top_k = min(k, logits.size(-1))\n",
    "    values, _ = torch.topk(logits, top_k)\n",
    "    min_values = values[:, -1].unsqueeze(-1)\n",
    "    logits[logits < min_values] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "\n",
    "def sample_sequence_feat(\n",
    "    model,\n",
    "    start_tokens,\n",
    "    max_len=200,\n",
    "    temperature=1.0,\n",
    "    top_k=20,\n",
    "    top_p=0.7,\n",
    "    greedy=False,\n",
    "    eos_id=None,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = list(start_tokens)\n",
    "    tokens_tensor = torch.tensor([tokens], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_len - len(tokens)):\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens_tensor)\n",
    "            next_logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # top-k / top-p filtering\n",
    "            next_logits = top_k_filtering(next_logits, top_k)\n",
    "            next_logits = top_p_filtering(next_logits, top_p)\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "            if greedy:\n",
    "                next_token = torch.argmax(probs, dim=-1).item()\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        tokens.append(next_token)\n",
    "        if eos_id is not None and next_token == eos_id:\n",
    "            break\n",
    "\n",
    "        next_token_tensor = torch.tensor([[next_token]], device=device)\n",
    "        tokens_tensor = torch.cat([tokens_tensor, next_token_tensor], dim=1)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "start_token = tokenizer.vocab[\"START\"]\n",
    "eos_token = tokenizer.vocab.get(\"END\", None)\n",
    "generations_inline = \"\"\n",
    "generations = []\n",
    "\n",
    "for i in range(5):\n",
    "    generated = sample_sequence_feat(\n",
    "        model,\n",
    "        start_tokens=[start_token],\n",
    "        max_len=200,\n",
    "        temperature=1.0,\n",
    "        greedy=False,\n",
    "        eos_id=eos_token,\n",
    "        device=device,\n",
    "    )\n",
    "    decoded_sketch = tokenizer.decode(generated, stroke_width=0.3)\n",
    "\n",
    "    decoded_sketch = stroke_to_bezier_single(decoded_sketch)\n",
    "    decoded_sketch = clean_svg(decoded_sketch)\n",
    "\n",
    "    # print(\"Generated token sequence:\", generated)\n",
    "    # print(\"Decoded sketch:\", decoded_sketch)\n",
    "    generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{decoded_sketch}</div>'\n",
    "    generations.append((generated, decoded_sketch))\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(generations_inline))\n",
    "\n",
    "# temp<=0.5 fairly deterministic\n",
    "\n",
    "# temp=0.8, top_k=20, top_p=0.9 more variety but still coherent\n",
    "\n",
    "# *note important features are usually preseved, but sketches are disorganized (number of curves hueristic does not work well)*\n",
    "# temp=1.0, top_k=20, top_p=0.75 more variety, some incoherent sequences\n",
    "\n",
    "#  *note that lower temp means less variety, notice that sequences begin to repete themselves more often*\n",
    "# temp=0.55, top_k=20, top_p=0.9 good balance\n",
    "# temp=0.6, top_k=30, top_p=0.9  good balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "db551456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M6,8C4.809017040378642,9.190982959621358 1.5702950877909254,12.111339903392157 1.0571458182308788,13.885708363538242C-0.42728177385010646,19.018564740820658 5.238974418155504,28.31421053042037 10.653377688099079,29C13.712765057751785,29.387502654839118 19.02708622599392,26.43384543533129 21.218807312719527,24.52079512485365C26.221323857912363,20.1543335856036 26.68184981525183,11.769892745684642 20.573000864515862,8.38200057634391C15.9433416298452,5.814448752040396 10.27354755272518,6.391807785650151 6,9M4,11C3.64327494054254,9.929824821627621 1.7278347885083232,1.0584858618222193 3.5713165621197356,1C5.57949502000709,0.9362890105648994 8.870960595599536,6.588700744499419 10,8M19,7C19.119806513075254,5.728826941845279 22.871599636799644,-3.239782095506138 24.845393685088073,-2C25.542481851865162,-1.5621440702443832 24.699724832012542,1.050963087956112 24.553717768247353,1.561987811134271C23.745260586610364,4.391587946863723 22.93072793832154,7.207816185035393 22,10M11,18C11,20.7720638498089 12.338783797849716,19.338783797849715 11,18C9.333333333333332,18 7.666666666666667,18 6,18M10,20C9.000000000000002,20.333333333333343 7.999999999999997,20.666666666666657 7,21M12,20C10.666666666666666,20.66666666666666 9.333333333333337,21.333333333333336 8,22M15,19C15.999999999999996,18.666666666666657 17.000000000000004,18.33333333333334 18,18M15,21C15.666666666666666,21 16.333333333333332,21 17,21M14,21C14.666666666666664,21.333333333333343 15.333333333333334,21.666666666666657 16,22M8,16C8.333333333333332,16 8.666666666666668,16 9,16M16,15C16.333333333333332,15 16.666666666666664,15 17,15\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M7,8C1.3944611065099828,8 -2.0245496377311953,17.63648571094233 4.114026230164825,20C9.691402732725095,22.147437670062367 14.821507441720776,9.718367966155075 7,8M3,9C2.6542265037883275,7.962679511364982 0.6212471173154408,2.337136789133082 2.9372682551001805,2.0627317448998195C5.022121000213691,1.8157158172775367 5,6.980025442871022 5,8M8,7C8.453296490565506,6.0934070188689855 10.265701749817975,-0.032621539863439075 11.831337151716745,1C13.140734415284513,1.863618577453287 10.37101292508937,7.886961224731892 10,9M4,13C4,15.145911184474024 6.145911184474024,13 4,13M4,15C5.469821308656478,16.469821308656478 6.2451010388837425,17.754898961116258 8,16M5,16C3.966529519319777,17.033470480680215 3.4406315586789313,17 2,17M11,14C12.797253864212442,13.64054922715751 14.780587045555977,13.006788350401369 16.62431331102645,13C28.354342806272985,12.9568116200743 23.461936009724283,29.323218406460285 13.447295409796913,24.585471557347685C11.86458818296011,23.836721155154702 10.268157182982918,22.17841043816425 9,21M24,19C24,14.368900195945898 24.42855943226907,9.523813522576974 29,8M9,23C8.66666666666667,24.000000000000004 8.33333333333333,24.999999999999996 8,26M12,23C12,24.333333333333332 12,25.66666666666667 12,27M16,24C16,25 16,26 16,27M22,22C22,23 22,24 22,25M25,20C25,20.66666666666667 25,21.33333333333333 25,22\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M5,8C3.8299146110353037,6.829914611035304 1.3680297881486756,1.4294803189527512 3.705593774323627,0.2944062256763733C5.321990500152962,-0.4904835393939213 7.513796618217296,5.027593236434592 8,6M9,7C9,3.246786090007933 16.981207722046943,5.495301930511736 19,6M19,5C20.761933795506614,-0.2858013865198039 24,-1.4240172025015072 24,5M24,6C32.32302640662283,14.323026406622843 17.208036446081014,20.818821813413575 9.865497822854014,18.93274891142701C3.993412512222343,17.42439035169113 2.520938102008899,11.396309219832586 6,7M16,11C16,12.968937568912713 15.968937568912711,13 14,13M17,11C17,13.453393081542288 17.546606918457712,14 20,14M21,11C22.459639259363787,10.270180370318107 23.36533974973326,10 25,10M21,13C22.333333333333336,12.666666666666666 23.666666666666668,12.333333333333332 25,12M23,15C23.666666666666668,15 24.333333333333332,15 25,15M5,8C3.333333333333332,8 1.6666666666666676,8 0,8M5,10C4.333333333333333,10 3.666666666666667,10 3,10M5,12C4.333333333333332,12.33333333333333 3.6666666666666683,12.666666666666668 3,13M6,13C5.666666666666667,13.333333333333334 5.333333333333334,13.666666666666666 5,14M7,3C7,3.6666666666666665 7,4.333333333333334 7,5\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M4,8C4,7.128576021437366 3.431049493957598,0.734726651466233 5.108361815949775,1.108361815949775C6.209510026381348,1.3536516688477123 8.171439182231985,4.1714391822319845 9,5M18,5C18,0.7554721444573049 24,-0.6818409459195571 24,5M6,10C6,5.801915705597676 17.63050171793862,6.815250858969307 20,8M2,12C2,21.41462443054925 15.656196704818935,22.615227348494756 21.6013353506396,17.265776432906932C24.22942489800643,14.90101475568492 24,12.235860881719493 24,9M7,12C8.284340358719529,13.284340358719529 9.42597944355138,12 8,12C5.333333333333332,12 2.666666666666668,12 0,12M8,13C4.874899845806496,13 2.3571042336873576,12.642895766312641 0,15M8,14C5.26253201028074,14 2.2242977747377655,16.55140445052446 1,19M13,12C14.637663862285853,11.18116806885708 16.263972587316186,10.578675804227945 18,10M13,13C15.579935257466051,13 17.547387355623172,13.182462451874391 20,14M13,15C14.333333333333336,15.33333333333333 15.666666666666664,15.666666666666666 17,16M4,8C4,7.666666666666666 4,7.333333333333335 4,7M3,7C3,8.015125165168984 3,8.015125165168982 3,7M10,6C10,7.015125165168984 10,7.015125165168984 10,6\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M7,8C10.207518685360514,4.792481314639487 14.074411815641406,2.658701202122149 18.75943438691854,4.586478128972846C23.567115389214763,6.56472612391444 25.890431291493915,14.033216885925608 23.39060337717255,18.60939662282745C20.813166809718474,23.32764659738026 13.623822494096503,26.00530713698777 9.174831759952875,22.087415879976437C4.642753952075739,18.09635609122308 5.606919553671151,11.658330376115575 8,7C6.830862083264918,5.830862083264918 4.168982855495605,-1.6735991018806864 8.031515095577491,0.03151509557749064C9.39581142657784,0.6337834778032087 10.932438108554223,2.932438108554222 12,4M17,4C17,2.9496985497929606 21.231273216250074,0.220524304848164 22,1.1306856256594116C23.023724867796645,2.3427609657118538 20.478082160294832,6.804794599262927 20,8M13,12C13,12.333333333333334 13,12.666666666666666 13,13M16,12C16.333333333333332,12 16.666666666666664,12 17,12M13,18C13.333333333333332,18 13.66666666666667,18 14,18\" fill=\"none\" stroke=\"#000000\" /></g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note many sketches have missing parts or incomplete shapes (step 1: get a base sketch) : check the number of paths\n",
    "\n",
    "# psuedo hueuristic: count number of curves in SVG\n",
    "\n",
    "from prepare_data import count_curves\n",
    "\n",
    "# sort generations by number of curves\n",
    "generations_inline = \"\"\n",
    "\n",
    "generations_sorted = sorted(generations, key=lambda x: count_curves(x[1]), reverse=True)\n",
    "for sketch in generations_sorted:\n",
    "    generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{sketch[1]}</div>'\n",
    "\n",
    "display(HTML(generations_inline))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
