{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632aa9ac",
   "metadata": {},
   "source": [
    "# Initial experiments Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651fca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import QuickDrawDataset\n",
    "from utils import DeltaPenPositionTokenizer\n",
    "from prepare_data import stroke_to_rdp, stroke_to_bezier_single, clean_svg\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c0017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0dd2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading QuickDraw files: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "Loading QuickDraw files: 3it [00:09,  3.07s/it]\n",
      "Tokenizing SVGs: 100%|██████████| 329852/329852 [01:47<00:00, 3064.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenized data to sketch_multi_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "labels = [\"bird\", \"crab\", \"guitar\"]\n",
    "training_data = QuickDrawDataset(labels=labels, download=True)\n",
    "tokenizer = DeltaPenPositionTokenizer(bins=32)\n",
    "\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        svg_list,\n",
    "        tokenizer,\n",
    "        max_len=200,\n",
    "        cache_file=\"sketch_multi_dataset.pkl\",\n",
    "    ):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = tokenizer.vocab[\"PAD\"]\n",
    "        self.parent = svg_list\n",
    "        self.num_labels = len(svg_list.label_map)\n",
    "\n",
    "        # Try to load from cache\n",
    "        try:\n",
    "            with open(cache_file, \"rb\") as f:\n",
    "                self.data = pickle.load(f)\n",
    "            print(f\"Loaded tokenized data from {cache_file}\")\n",
    "        except FileNotFoundError:\n",
    "            for svg in tqdm(svg_list, desc=\"Tokenizing SVGs\"):\n",
    "                # use RDP to reduce number of points in SVG (already applied for quickdraw)\n",
    "                # svg = stroke_to_rdp(svg, epsilon=1.0)  # tuning\n",
    "                tokens = tokenizer.encode(svg)[:max_len]\n",
    "                tokens = tokens + [self.pad_id] * (max_len - len(tokens))\n",
    "                self.data.append(tokens)\n",
    "\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(self.data, f)\n",
    "            print(f\"Saved tokenized data to {cache_file}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        input_ids = torch.tensor(seq[:-1])\n",
    "        target_ids = torch.tensor(seq[1:])\n",
    "        return input_ids, target_ids, self.parent.labels[idx]  # integer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = SketchDataset(training_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d81d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Epoch 1/15: 100%|██████████| 2577/2577 [14:29<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 2577/2577 [14:22<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 1.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 2577/2577 [14:35<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 2577/2577 [14:22<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 1.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 2577/2577 [14:27<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 1.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 2577/2577 [14:14<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 2577/2577 [14:14<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 2577/2577 [14:15<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 2577/2577 [14:15<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15:  72%|███████▏  | 1867/2577 [10:20<03:55,  3.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     70\u001b[39m model = SketchTransformer(\n\u001b[32m     71\u001b[39m     vocab_size=\u001b[38;5;28mlen\u001b[39m(tokenizer.vocab), num_classes=dataset.num_labels, d_model=\u001b[32m512\u001b[39m, nhead=\u001b[32m8\u001b[39m, num_layers=\u001b[32m8\u001b[39m\n\u001b[32m     72\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# d_model => model capacity (types of drawing features it can learn)\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# nhead => model can attend to more positions in parallel\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# num layers => model learns more hierarchical abstractions (patterns, shapes , layouts)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, dataloader, vocab_size, epochs, lr, device)\u001b[39m\n\u001b[32m     62\u001b[39m     loss.backward()\n\u001b[32m     63\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss/\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def generate_square_subsequent_mask(sz: int):\n",
    "    \"\"\"Causal mask to stop attention to future positions\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "\n",
    "\n",
    "class SketchTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, num_classes, d_model=512, nhead=8, num_layers=6, max_len=200\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.class_embed = nn.Embedding(num_classes, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=4 * d_model\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, class_labels):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len) input tokens\n",
    "        class_labels: (batch,) integer labels for conditioning\n",
    "        Returns: (batch, seq_len, vocab_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0)\n",
    "        x = self.embed(x) + self.pos_embed(positions)\n",
    "        class_cond = self.class_embed(class_labels).unsqueeze(1)  # (batch, 1, d_model)\n",
    "        x = x + class_cond  # simple additive conditioning\n",
    "        x = x.transpose(0, 1)  # (seq_len, batch, d_model)\n",
    "        mask = generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        x = x.transpose(0, 1)  # back to (batch, seq_len, d_model)\n",
    "\n",
    "        logits = self.fc_out(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, vocab_size, epochs=10, lr=1e-4, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for input_ids, target_ids, class_labels in tqdm(\n",
    "            dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"\n",
    "        ):\n",
    "            input_ids, target_ids, class_labels = (\n",
    "                input_ids.to(device),\n",
    "                target_ids.to(device),\n",
    "                class_labels.to(device),\n",
    "            )\n",
    "\n",
    "            logits = model(input_ids, class_labels)\n",
    "            loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "model = SketchTransformer(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    num_classes=dataset.num_labels,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_layers=8,\n",
    ")\n",
    "\n",
    "# d_model => model capacity (types of drawing features it can learn)\n",
    "# nhead => model can attend to more positions in parallel\n",
    "# num layers => model learns more hierarchical abstractions (patterns, shapes , layouts)\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    dataloader,\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    epochs=15,\n",
    "    lr=1e-4,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"sketch_transformer_model_cond_v2_deep.pth\")\n",
    "# model = torch.load(\n",
    "#     \"sketch_transformer_model_cond_v2_deep.pth\", map_location=device, weights_only=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1502569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated bird</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M0,7C2.3782811020613703,0.6974300652615364 7.529299616847347,2.740315807780016 12.180593391616155,3.590296695808077C14.01218842621078,3.9250037363432466 16.471007705528596,0.9807765354460072 18.294833405356712,0.35258329732164473C23.05774787964456,-1.2879411600287787 26.278906677480194,1.5192711183201273 30,4\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated bird</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M0,4C4.033679630664401,1.9831601846677995 9.822859989819815,-1.9707018491086687 14.408791343854059,0.7043956719270299C15.07991182013522,1.0958783575186264 17.902943588169457,4.936541954874626 18.0470917913808,4.9529082086192C19.298203438280765,5.094956532634287 19.89338353956419,3.1656411010800176 21.043134467939865,2.6522885106867116C25.093972296372307,0.8436288773982714 28.117702085730993,1.058851042865499 32,3\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated bird</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M0,7C1.9187247337054711,5.081275266294529 5.143111257595251,2.283146168260622 8.156551521828723,3.0782757609143614C8.944482881396443,3.286180177805649 12.90131664669581,7.029878291468487 13,6.986616740796843C14.392021177408266,6.3763720269106265 13.411602589644737,3.820077381156249 14.364239034668424,2.6357609653315763C16.56223801334312,-0.09678856708273198 19.82237835615844,0 23,0M11,20C11.870319505120593,18.259360989758814 14.656389815927293,15.48390745875685 17.023308793247796,17.04661758649559C17.621323246722348,17.441444469854634 17.269570288516007,18.92399030817621 17.984722958889986,18.96944591777997C19.028734068703354,19.035804002417827 18.94844058691092,17.07784129683664 19.674899950642768,16.325100049357232C21.649415795102982,14.279150070418744 23.05907811358408,13 26,13\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated bird</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M4,3C2.9805520990521837,3.5097239504739077 -1.3231058563892182,6.093243762124808 0,7.895939702297154C0.49055093054292714,8.564302076076386 5.1221730622751735,8 6,8M5,3C5,1.3418115606942635 7.179884423705223,-0.7534359186433729 8.999674105128827,0C11.62129196615898,1.0854117273112187 11.595948319829382,7.4040516801706175 10,9M5,7C7.649805255979265,10.133058121271969 5.923322252301709,14.45301918930414 9.168171989558095,17.0560573298527C15.482617803720096,22.121544061632346 25.43173502257221,10.76366430363791 14.783559253141522,8.26118641771384C13.296989158104871,7.911820585550821 12.513969229094196,8 11,8C11.663427451781178,11.231490121995716 17.196353656969738,14.912724725215035 20.573325707396872,14C24.525590729270093,12.931785649333415 19.79693676701649,10.655013767016806 18.560345055194333,10.186781685064778C17.710546944065314,9.865007945997323 16.966677273094792,9.26637265186079 16.085895525065947,9.042947762532973C14.890498951885633,8.739715608070894 13.22939063193402,9 12,9M11,15C11,16.666666666666664 11,18.333333333333332 11,20M15,16C15,17 15,18 15,19M11,20C10.333333333333337,20.333333333333343 9.666666666666663,20.666666666666657 9,21M12,20C12.333333333333334,20.666666666666668 12.666666666666666,21.333333333333332 13,22M12,21C11.666666666666668,21.333333333333343 11.33333333333333,21.666666666666657 11,22M14,21C14.333333333333334,21.666666666666668 14.666666666666666,22.333333333333332 15,23M14,21C14,21.666666666666668 14,22.333333333333332 14,23M16,20C16,20.33333333333334 16,20.666666666666664 16,21M16,20C16,20.33333333333334 16,20.666666666666664 16,21M17,20C17,20.33333333333334 17,20.666666666666664 17,21M17,19C17.333333333333336,19.333333333333336 17.666666666666668,19.666666666666668 18,20M18,18C18.333333333333336,18.333333333333336 18.666666666666664,18.666666666666664 19,19\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated bird</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M4,3C-0.02473482889234191,5.683156552594893 -0.3470839071328182,7 5,7M4,3C4,0.7271245695006416 7.218521567481164,-0.4953050535960566 9.237896165877048,0.11894808293852376C12.518927154714074,1.116971717365363 14.506292063058135,7.493707936941865 12,10M5,7C5,14.822265369135646 9.17773463086436,19 17,19M12,8C15.40237647747259,11.40237647747259 17,13.065169116356413 17,18C17.926660663025466,17.536669668487267 23.625875346714814,16.079953117835323 22.886848461444746,19.113151538555254C22.52372955667596,20.6035055573752 19.07839013589055,20 18,20M11,19C13.078073316049437,23.156146632098874 15.577380065511942,24 20,24M12,22C12,24.109979223689024 11.510301855861904,25.95879257655241 11,28C9.365339749733263,28 8.459639259363783,28.270180370318098 7,29M12,28C11.333333333333336,28.666666666666664 10.666666666666666,29.333333333333336 10,30M12,29C12,29.333333333333336 12,29.666666666666664 12,30M18,23C18,24.999999999999996 18,27 18,29C17.333333333333336,29.333333333333343 16.666666666666664,29.666666666666657 16,30M18,29C18,29.333333333333336 18,29.666666666666664 18,30M18,28C18.33333333333334,28.666666666666657 18.666666666666657,29.33333333333334 19,30\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated crab</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M16,1C14.03685425855767,1 11.677289873083549,0.4389418387910584 10.071426942592293,1.9285730574077067C5.1682451823801525,6.476864497405861 13.513086768859097,10.647547134004052 17.403015713346644,10C26.58356671153806,8.471735712324161 22.39303276411998,0.11627937744415265 15,0M11,2C7.051556057938255,-1.9484439420617448 0,-0.16552156020288677 0,6M8,5C4.373891592587535,3.1869457962937675 1.5878624368534242,6.8242751262931485 0,10M8,8C4.936979456906528,8 4,10.340360889087277 4,13M21,1C21,-4.125084384297517 28.59726001228653,1.5972600122865273 30,3M22,5C25.085596976302785,3.4572015118486084 25.753559972525245,4.7535599725252515 28,7M21,7C23.77099571422722,7 25.094106724676053,8.094106724676053 27,10M10,9C10,7.984874834831016 10,7.984874834831016 10,9M10,11C7.874965470431515,13.125034529568484 7.560378999630969,21.87053591786801 12.705610964617293,20.852805482308646C13.942988267471073,20.608051397370517 12.088430938517975,17.473055398217248 12.133532243043527,17.267064486087055C12.273335297266053,16.628542852160276 13.518830612977025,18.310803628568934 14,17.868388900113377C14.640308338987309,17.279652692946122 10.806524955946387,14.2110060754504 13,12M20,12C21.590761734304564,13.590761734304554 19.755481206511426,18 21,18\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated crab</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M19,8C16.210856038727293,7.07028534624243 13.253115435292417,6.359052691342403 10.45770348081373,7.8474321730620895C5.941143578894438,10.252213720627662 11.169464404462117,14.075116043332617 13.957660404480716,14.652553468160239C18.822957314841812,15.66016000619485 24.556960931882063,8 18,8M11,9C10.333333333333334,8.333333333333334 9.666666666666663,7.666666666666669 9,7C9.944785755369235,6.055214244630764 12.81820516725447,3.1788046090553577 10.075981621783997,2.075981621783998C6.759267157518897,0.7421191949046395 9.667997317994478,5.525816307002188 7.80069491766297,5C6.722679716259921,4.69644018451787 6.23976200454752,2.161809166693929 5.613518644710121,2C3.7588133792724467,1.5207800470072297 2.2470238837662446,5.228006103146993 3.4901951841570935,6.490195184157093C4.3837885459596535,7.397458554680284 7.830265594837877,8 9,8M21,9C22.441643710858653,8.279178144570674 24,7.7883859467472 24,6C21.67465269096106,5.4072117006485705 21.12826715145174,0.7047404089460776 23.76905669874236,1C25.674670431468805,1.2130615565366853 24.25146206792332,4.191054957719125 25.806446079538414,4C27.190558241440304,3.8299394150708808 28.05728090235191,-0.8898606769038282 29.77190260339883,1.7719026033988303C32.01384659893408,5.252276262595541 26.73257179711952,8.554631291129521 24,6\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated crab</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M19,8C15.162070298893394,6.172094459591008 10.784003064119494,7.452507828766274 8.07128806900037,10.92871193099963C6.1070402736098846,13.44579398953685 6.6367375451727675,18.242911648132843 9.75534404137273,19.75534404137273C14.637945766135985,22.1232622191932 26.573073682025523,15.326527805118154 22.24845218484784,9.49690436969568C21.657165065233325,8.699844730645705 18.79582403183885,7.397912015919425 18,7M10,9C6.535392753973965,9 5.233595778662949,6.071893931917659 6.085879388580905,2.8282412228381917C6.327285260091558,1.9094897649888514 7.3775163937964825,0.12509766226915317 6.4358521165750835,0C4.726049164668371,-0.22714289731321932 5.091953456184071,2.08452135607166 4.213745713934284,2.5725085721314307C3.872561996416331,2.7620916109349696 1.8578173966579938,1.1916709893904438 1.786590478822188,1.213409521177812C-0.27782776437654677,1.8434721852067562 1.6975231688124017,3.6499351737573718 2.0576739092346408,4.057673909234641C4.397540884876093,6.706715809619293 5.769893718132143,10.384946859066073 9,12M22,8C23.49698181244872,6.5786548969615835 25.557259324152493,6.0293472466697136 26,3.726774694428692C26.11102540878132,3.1493620625943883 25.320424730187035,-0.2921665348947979 26.892906422779294,0C29.03985807028688,0.3989028466238665 27.322255328438835,1.5071812121692016 28,2.5584802718781905C28.2988906709166,3.0221113330661815 30.778980451102598,0.780144744498966 31,3.3497342643399888C31.181900238869307,5.464519810627195 24.608251753515525,9.195874123242238 23,10M8,13C5.672539199945813,14.16373040002709 3.8469820232093825,15.153017976790617 2,17M10,16C7.67334912383804,16 5.546657223968361,18.45334277603165 4,20M10,19C8.345967172358941,19.827016413820523 7.827016413820531,20.34596717235895 7,22M26,12C28.308017193318115,12 29.91786951286402,11.95893475643201 32,13M24,14C25.66666666666667,14 27.33333333333333,14 29,14M23,16C24.710409700458328,16 25.760425852142795,15.760425852142795 27,17\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated crab</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M17,7C12.492172412392804,7 8.502134497509624,7.467513599529194 5.1619388394497605,10.83806116055024C1.5259809187102706,14.507058535644726 3.790556009853825,18.905621814688573 8.60057831732206,20C16.566527134371796,21.812415837895603 26.147413248311864,14.098275498874575 17,8M20,10C23.038497644750006,10 25,9.39188986233749 25,6C24.0709161283464,5.919667201613031 20.676635398970667,3.2635525469170648 22.018982609302128,2C23.028470006599385,1.0497686722791637 23.322226387442242,2.985191325776879 23.909826000263376,2.9098260002633776C24.89519026156321,2.7834435168820644 24.003706459883325,0.5257363200300166 24.900877512421943,0.09912248757805686C29.354911622219092,-2.018815397372291 27.600126010502617,5.399873989497383 26,7M5,12C1.8016189153215247,10.400809457660756 1.447547063111399,8.104905873777202 3,5C1.6188092711496955,3.618809271149695 2.0022379127443877,-0.48438405369312504 4.714485054109514,0C6.627287940535643,0.341610173318003 5.1280013527430945,1.3564125700744958 5.093562073287686,1.906437926712314C5.032699201960957,2.8784711119834885 8.02610319933523,0.6335288066979926 8,1.6071156930923318C7.956765405786836,3.2196626236023365 5.098164137099769,3.63394528763341 4,4M4,16C2.320207165671376,16 1,19.38382967138974 1,21M6,19C4.320207165671377,19 3,22.38382967138974 3,24M7,22C5.966529519319781,23.03347048068021 6,23.559368441321073 6,25M21,17C22.654032827641057,17.827016413820527 23.17298358617947,18.345967172358943 24,20M20,19C20.72031577933946,19.72031577933946 21,19.966529519319785 21,21M17,20C17.33333333333334,20.666666666666657 17.666666666666657,21.33333333333334 18,22M22,12C23.039394106541433,12.519697053270717 23.826474451889354,13 25,13M23,10C23.999999999999996,10 25,10 26,10\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated crab</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M19,7C15.919031335804204,7 12.230456417339864,6.5423713876372815 9.631583014706566,8.684208492646718C4.7750110965090515,12.686706623953349 7.18021601202685,17.871492213854136 12.6757216296235,18.8919072098745C21.46914419636839,20.524685133841846 26.707429732952097,11.64851998224892 18,7M10,10C7.268132959437866,8.634066479718934 5.234042433727768,8.765957566272231 3,11M9,12C5.5621124105232935,12 3.4459430247016387,14.10811395059671 2,17M9,15C6.952277965180435,15 5.823673297870205,17.3526534042596 5,19M26,7C28.21539440518964,7 33,6.903998234852693 33,10M25,10C27.58892583139745,10 30.14594967837963,11.145949678379628 32,13M25,13C26.333333333333332,13.666666666666666 27.666666666666668,14.333333333333334 29,15M15,6C15,4.666666666666666 15,3.333333333333335 15,2M14,1C10.109635806363418,1 14,5.537390135203255 14,1M20,7C20,6.000000000000002 20,4.999999999999999 20,4M20,2C15.684492122530429,2 24.108921618261892,6.108921618261911 20,2M11,13C9.862752368595105,13.568623815702447 9,13.65635042042685 9,15M13,14C12.279684220660537,14.720315779339463 12,14.966529519319783 12,16M14,15C13.666666666666668,15.666666666666664 13.333333333333334,16.333333333333332 13,17M24,12C25.34364957957316,12 25.43137618429754,12.862752368595105 26,14M23,13C23.333333333333343,13.666666666666664 23.666666666666657,14.333333333333336 24,15M22,13C22,13.666666666666664 22,14.333333333333334 22,15M24,5C25.252879943847518,3.7471200561524833 26.4155146446262,-2.2054169012924465 24.029908558494423,0C22.624167482790305,1.2995628847618688 24.54359024321932,5.456409756780681 27,3M28,2C28.333333333333336,1.6666666666666758 28.666666666666664,1.3333333333333277 29,1C29,0.6666666666666665 29,0.3333333333333335 29,0\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated guitar</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M6,12C0.04720931075550627,13.984263563081498 3.5447218412877923,16.280989050435984 2.538402462300504,20.692396306549245C0.9781917392000814,27.531899796860014 0.740868134136428,18.535048481540343 0.06400036830890454,25.807998895073286C-0.5339350799797562,32.232820825513905 10.288039455174008,32.527372643086096 13.239092883746927,28.521814232506145C15.616056234293577,25.295486491965484 12.533836545306361,23.576160171667034 11.521454330797072,21.042908661594144C9.64574785254626,16.349388565742267 13.599194148412,15.309962492689703 8,12C8,8.33333333333333 8,4.66666666666667 8,1C8.666666666666666,1 9.333333333333334,1 10,1C10,4.7762325877102825 9,8.250026055758035 9,12\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated guitar</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M0,2C0.6827830767915077,5.286624813751446 8.83100913974291,10.154806097711155 10,4.93261544474792C10.954968045803346,0.6665211815506531 3.3932169010341298,-1.3932169010341293 1,1M6,3C3.8533307225716933,5.146669277428304 7.143170835190085,7.152906443598785 8,5.898477253256077C8.962984018495188,4.488633480137226 7.196232621841655,3 6,3M2,2C2,2.3333333333333335 2,2.666666666666667 2,3M2,2C2,2.3333333333333335 2,2.666666666666667 2,3M3,3C3,3.333333333333333 3,3.666666666666667 3,4M4,3C4,3.333333333333333 4,3.666666666666667 4,4M6,3C6,3.6666666666666665 6,4.333333333333334 6,5M9,3C9,3.333333333333333 9,3.666666666666667 9,4\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated guitar</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M0,3C2.3325583428162955,-1.665116685632591 3.6098920152106007,3.2688542100735813 6.082122292100677,2.9178777078993225C8.978290905589398,2.5067157141436978 8.78985334918236,-0.4202933016352892 11,4M-1,3C-1,5.308064652032863 0.9319595694917528,8.31000665426043 3.8048319087241076,7C4.349547370738694,6.7516141353818995 4.517108514245352,4.972587407272761 5.304929948523513,5.304929948523513C6.822892269057874,5.945282486775419 11,9.01414999486381 11,5M11,3C15.333333333333334,3 19.666666666666664,3 24,3M12,5C15.999999999999998,5 20.000000000000004,5 24,5C24,9.69922783133 31.975901861094037,3 24,3\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated guitar</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M7,12C-0.9945475087602977,12 2.9867071719970406,16.19986769031398 1.4135758703018366,21.172848259396325C0.37188664490494117,24.46583484693604 -1.8051912372984544,29.095976429240984 3.5826028277725808,30C6.540859910561681,30.496369033208566 12.414247817664657,29.246360301581518 12,25.153339402470774C11.515959572698456,20.370724985504737 10.039260087350957,25.341134256092307 10,20.373971267156723C9.969536979682736,16.51980798681393 14.800256773708142,13.76754472798676 9,12M5,12C5.333333333333332,8.999999999999998 5.66666666666667,6 6,3M8,10C8,8 8,6 8,4M5,4C-1.9792990503812318,4 7,-4.092548662526323 7,3M5,1C5,2.9999999999999996 5,5.000000000000001 5,7M5,1C5,3.3333333333333335 5,5.666666666666666 5,8M5,4C5,5.333333333333336 5,6.666666666666664 5,8M6,3C6,5.333333333333334 6,7.666666666666665 6,10M6,6C6,6.666666666666666 6,7.333333333333334 6,8M5,17C4.680618624272591,17.63876275145482 4.1411266683940635,18.408612480958723 4,19.115446058341078C2.4883074681446766,26.686765160198625 13.266017632823479,17 5,17\" fill=\"none\" stroke=\"#000000\" /></g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated guitar</b><br><svg viewBox=\"0 0 32 32\" xmlns=\"http://www.w3.org/2000/svg\"><g stroke-width=\"0.3\"><path d=\"M4,14C2.5402952047087455,15.459704795291255 0.07141010668130651,17.259083511444558 0,19.582159780089754C-0.09394465926423755,22.638318335862355 5.123668900651184,23.865204846714597 7.420159817160052,23C8.434686240750345,22.617776333230726 9.705190762900596,20.339754918583814 10.466760560728076,19.766619719635962C11.717556264104685,18.825307385109447 13.626819637161491,19.043526470950905 14.839439301780365,18.053520232739878C18.304432640271322,15.224632395477347 15.077732072070045,12.34917241435601 12.279831147438783,11.569957786859696C8.517324745247967,10.52210080278082 6.697531371409035,11.302468628590965 4,14M15,11C19.57655741503848,8.71172129248076 24.334050858781772,2.627410795498933 28.86362490899576,1.1363750910042396C29.929910635945216,0.7853773873681529 31.46345794492525,1.7683983972037711 30.84326736166205,3.1044884255586327C30.31062052052899,4.251981071009815 28.731046097876753,4.497893503247511 27.692193786987605,5.21986158072314C24.495815923325,7.441238726372471 21.732098525198985,9.755967158267005 18,11M8,16C6.66552262306474,17.33447737693526 6.833892252152666,20.455729238185793 9.195110883220345,18.804889116779655C10.33968391711105,18.004663732579658 10.562397520952231,16 9,16M6,19C9.735693281004485,16.7585840313973 13.375314631879512,14.416456912080326 17,12M7,20C9.618807246484078,17.90495420281274 12.208656960028385,15.860895359981084 15,14M8,21C9.913541127266026,19.086458872733964 11.747000259433719,17.501999827044195 14,16\" fill=\"none\" stroke=\"#000000\" /></g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def top_p_filtering(logits, p=0.9):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "    sorted_indices_to_remove = cumulative_probs > p\n",
    "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "    sorted_indices_to_remove[..., 0] = False\n",
    "    indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "    logits[:, indices_to_remove] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "\n",
    "def top_k_filtering(logits, k):\n",
    "    if k <= 0:\n",
    "        return logits\n",
    "    top_k = min(k, logits.size(-1))\n",
    "    values, _ = torch.topk(logits, top_k)\n",
    "    min_values = values[:, -1].unsqueeze(-1)\n",
    "    logits[logits < min_values] = -float(\"Inf\")\n",
    "    return logits\n",
    "\n",
    "\n",
    "def sample_sequence_feat(\n",
    "    model,\n",
    "    start_tokens,\n",
    "    class_label,\n",
    "    max_len=200,\n",
    "    temperature=0.8,\n",
    "    top_k=20,\n",
    "    top_p=0.7,\n",
    "    greedy=False,\n",
    "    eos_id=None,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = list(start_tokens)\n",
    "    tokens_tensor = torch.tensor([tokens], device=device, dtype=torch.long)\n",
    "    class_label_tensor = torch.tensor([class_label], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_len - len(tokens)):\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens_tensor, class_label_tensor)\n",
    "            next_logits = logits[:, -1, :] / temperature\n",
    "\n",
    "            # top-k / top-p filtering\n",
    "            next_logits = top_k_filtering(next_logits, top_k)\n",
    "            next_logits = top_p_filtering(next_logits, top_p)\n",
    "\n",
    "            probs = F.softmax(next_logits, dim=-1)\n",
    "\n",
    "            if greedy:\n",
    "                next_token = torch.argmax(probs, dim=-1).item()\n",
    "            else:\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        tokens.append(next_token)\n",
    "        if eos_id is not None and next_token == eos_id:\n",
    "            break\n",
    "\n",
    "        # Append new token for next iteration\n",
    "        next_token_tensor = torch.tensor([[next_token]], device=device)\n",
    "        tokens_tensor = torch.cat([tokens_tensor, next_token_tensor], dim=1)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "start_token = tokenizer.vocab[\"START\"]\n",
    "eos_token = tokenizer.vocab.get(\"END\", None)\n",
    "generations_inline = \"\"\n",
    "generations = []\n",
    "\n",
    "labels = [\"bird\", \"crab\", \"guitar\"]\n",
    "\n",
    "for j, label in enumerate(labels):\n",
    "    for i in range(5):\n",
    "        generated = sample_sequence_feat(\n",
    "            model,\n",
    "            start_tokens=[start_token],\n",
    "            class_label=j,\n",
    "            max_len=200,\n",
    "            greedy=False,\n",
    "            eos_id=eos_token,\n",
    "            device=device,\n",
    "        )\n",
    "        decoded_sketch = tokenizer.decode(generated, stroke_width=0.3)\n",
    "\n",
    "        decoded_sketch = stroke_to_bezier_single(decoded_sketch)\n",
    "        decoded_sketch = clean_svg(decoded_sketch)\n",
    "\n",
    "        # print(\"Generated token sequence:\", generated)\n",
    "        # print(\"Decoded sketch:\", decoded_sketch)\n",
    "        generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated {label}</b><br>{decoded_sketch}</div>'\n",
    "        generations.append((generated, decoded_sketch))\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(generations_inline))\n",
    "\n",
    "# temp<=0.5 fairly deterministic\n",
    "\n",
    "# temp=0.8, top_k=20, top_p=0.9 more variety but still coherent\n",
    "\n",
    "# *note important features are usually preseved, but sketches are disorganized (number of curves hueristic does not work well)*\n",
    "# temp=1.0, top_k=20, top_p=0.75 more variety, some incoherent sequences\n",
    "\n",
    "#  *note that lower temp means less variety, notice that sequences begin to repete themselves more often*\n",
    "# temp=0.55, top_k=20, top_p=0.9 good balance\n",
    "# temp=0.6, top_k=30, top_p=0.9  good balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db551456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note many sketches have missing parts or incomplete shapes (step 1: get a base sketch) : check the number of paths\n",
    "# psuedo hueuristic: count number of curves in SVG\n",
    "\n",
    "from prepare_data import count_curves\n",
    "\n",
    "# sort generations by number of curves\n",
    "generations_inline = \"\"\n",
    "\n",
    "generations_sorted = sorted(generations, key=lambda x: count_curves(x[1]), reverse=True)\n",
    "for sketch in generations_sorted:\n",
    "    generations_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{sketch[1]}</div>'\n",
    "\n",
    "display(HTML(generations_inline))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
