{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632aa9ac",
   "metadata": {},
   "source": [
    "# Initial experiments: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651fca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import QuickDrawDataset\n",
    "from utils import AbsolutePenPositionTokenizer\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c0017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0dd2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading QuickDraw files: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized data from sketch_tokenized_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "labels = [\"cat\"]\n",
    "\n",
    "training_data = QuickDrawDataset(\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "tokenizer = AbsolutePenPositionTokenizer(bins=64, additional_tokens=[\"MASK\"])\n",
    "\n",
    "\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        svg_list,\n",
    "        tokenizer,\n",
    "        max_len=200,\n",
    "        cache_file=\"sketch_tokenized_dataset.pkl\",\n",
    "    ):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = tokenizer.vocab[\"PAD\"]\n",
    "\n",
    "        # Try to load from cache\n",
    "        try:\n",
    "            with open(cache_file, \"rb\") as f:\n",
    "                self.data = pickle.load(f)\n",
    "            print(f\"Loaded tokenized data from {cache_file}\")\n",
    "        except FileNotFoundError:\n",
    "            for svg in tqdm(svg_list, desc=\"Tokenizing SVGs\"):\n",
    "                tokens = tokenizer.encode(svg)\n",
    "                # Truncate + pad\n",
    "                tokens = tokens[:max_len]\n",
    "                tokens = tokens + [self.pad_id] * (max_len - len(tokens))\n",
    "                self.data.append(tokens)\n",
    "\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(self.data, f)\n",
    "            print(f\"Saved tokenized data to {cache_file}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = SketchDataset(training_data, tokenizer, max_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d81d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_input(input_ids, tokenizer, mask_prob=0.2, dropout_prob=0.05):\n",
    "    mask_token = tokenizer.vocab.get(\"MASK\", None)\n",
    "    pad_token = tokenizer.vocab[\"PAD\"]\n",
    "    assert mask_token is not None, \"Tokenizer must have a [MASK] token\"\n",
    "\n",
    "    batch_size, seq_len = input_ids.shape\n",
    "    device = input_ids.device\n",
    "\n",
    "    rand = torch.rand(batch_size, seq_len, device=device)\n",
    "    mask = (rand < mask_prob) & (input_ids != pad_token)\n",
    "    dropout = (rand < dropout_prob) & (input_ids != pad_token)\n",
    "\n",
    "    # Create masked input\n",
    "    corrupted = input_ids.clone()\n",
    "    corrupted[mask] = mask_token\n",
    "    # Remove some tokens (simulate missing strokes or words)\n",
    "    corrupted[dropout] = pad_token\n",
    "    return corrupted\n",
    "\n",
    "\n",
    "class SketchAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=6, max_len=200):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,  # much easier shape handling\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(0, seq_len, device=x.device).unsqueeze(0)\n",
    "        x = self.embed(x) + self.pos_embed(pos)\n",
    "        h = self.encoder(x)\n",
    "        h = self.norm(h)\n",
    "        logits = self.fc_out(h)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95801f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 1610/1610 [03:21<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | DAE Loss: 1.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 1610/1610 [03:24<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | DAE Loss: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 1610/1610 [03:26<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | DAE Loss: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 1610/1610 [03:28<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | DAE Loss: 0.8709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 1610/1610 [03:28<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | DAE Loss: 0.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 1610/1610 [03:27<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | DAE Loss: 0.8335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:   3%|▎         | 45/1610 [00:05<03:25,  7.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m dataloader = DataLoader(dataset, batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     28\u001b[39m model = SketchAutoencoder(vocab_size=\u001b[38;5;28mlen\u001b[39m(tokenizer.vocab), d_model=\u001b[32m256\u001b[39m, nhead=\u001b[32m8\u001b[39m, num_layers=\u001b[32m6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mtrain_denoising_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_denoising_autoencoder\u001b[39m\u001b[34m(model, dataloader, tokenizer, epochs, lr, device)\u001b[39m\n\u001b[32m     20\u001b[39m     loss.backward()\n\u001b[32m     21\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | DAE Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train_denoising_autoencoder(\n",
    "    model, dataloader, tokenizer, epochs=10, lr=1e-4, device=\"cuda\"\n",
    "):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    pad_token_id = tokenizer.vocab[\"PAD\"]\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "    vocab_size = len(tokenizer.vocab)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for clean_ids in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            clean_ids = clean_ids.to(device)\n",
    "            noisy_ids = corrupt_input(clean_ids, tokenizer)\n",
    "\n",
    "            logits = model(noisy_ids)\n",
    "            loss = criterion(logits.reshape(-1, vocab_size), clean_ids.reshape(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | DAE Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "model = SketchAutoencoder(\n",
    "    vocab_size=len(tokenizer.vocab), d_model=256, nhead=8, num_layers=6\n",
    ")\n",
    "\n",
    "train_denoising_autoencoder(\n",
    "    model, dataloader, tokenizer, epochs=20, lr=1e-3, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ae5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 32 18 L 28 10 L 24 7 L 27 19 L 19 20 L 15 23 L 14 25 L 12 30 L 12 33 L 13 37 L 15 41 L 21 45 L 33 47 L 38 46 L 42 44 L 50 37 L 53 32 L 54 28 L 53 25 L 51 22 L 46 19 L 43 0 L 40 8 L 39 16 L 32 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 33 L 7 32 L 2 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 39 L 11 40 L 0 43\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 43 L 13 47 L 9 50\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 33 L 54 32 L 61 33 L 62 34\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 36 L 63 39\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 42 40 L 51 49 L 53 52\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 32 32 L 27 33 L 27 34 L 27 35 L 32 36 L 34 35 L 34 33 L 29 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 26 24 L 26 28\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 32 18 L 28 10 L 24 7 L 27 19\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 16 22 L 14 25 L 12 30 L 12 33 L 13 37 L 15 41 L 21 45 L 28 46 L 38 46 L 42 44 L 50 37 L 53 32 L 53 28 L 53 25 L 48 23 L 46 19 L 43 0 L 40 8 L 39 16 L 32 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 33 L 7 32 L 2 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 39 L 6 40 L 0 43\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 43 L 13 47 L 9 50\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 33 L 54 32 L 61 33 L 62 34\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 36 L 63 41\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 42 40 L 51 49 L 53 52\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 32 32 L 27 33 L 27 34 L 27 35 L 32 36 L 34 35 L 34 33 L 29 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 26 24 L 26 28\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 32 18 L 28 10 L 24 7 L 27 19 L 19 20 L 15 23 L 14 25 L 12 30 L 12 33 L 13 37 L 15 41 L 21 45 L 33 47 L 38 46 L 42 44 L 50 37 L 53 32 L 54 28 L 53 25 L 51 22 L 46 19 L 43 0 L 40 8 L 39 16 L 32 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 33 L 6 32 L 1 42\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 39 L 6 40 L 0 43\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 43 L 13 47 L 5 50\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 33 L 54 32 L 61 33 L 62 34\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 36 L 63 39\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 42 40 L 51 49 L 55 55\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 32 32 L 27 33 L 27 34 L 27 35 L 32 36 L 34 35 L 34 33 L 29 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 26 24 L 25 23\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 32 18 L 28 10 L 22 0 L 22 14 L 19 20 L 16 22 L 14 25 L 12 30 L 12 33 L 13 37 L 15 41 L 21 45 L 33 47 L 38 46 L 42 44 L 50 37 L 53 32 L 53 28 L 53 25 L 51 22 L 45 9 L 43 0 L 40 8 L 39 16 L 32 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 33 L 7 32 L 2 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 39 L 6 40 L 0 43\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 43 L 13 47 L 7 54\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 33 L 54 32 L 61 33 L 62 34\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 36 L 63 41\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 42 40 L 50 45 L 59 48\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 32 32 L 27 33 L 27 34 L 27 35 L 32 36 L 34 35 L 34 33 L 29 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 26 29 L 26 28\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div><div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br><svg viewBox=\"0 0 64 64\"><g stroke-width=\"0.8\">\n",
       "<path d=\"M 32 18 L 28 10 L 27 14 L 27 19 L 19 20 L 16 22 L 13 24 L 12 30 L 10 34 L 13 37 L 15 41 L 24 45 L 33 47 L 38 46 L 42 44 L 50 37 L 53 33 L 53 28 L 53 25 L 48 23 L 46 19 L 43 0 L 40 8 L 39 16 L 32 17\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 33 L 7 32 L 2 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 19 39 L 6 40 L 0 43\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 21 43 L 13 47 L 9 50\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 33 L 54 32 L 61 33 L 62 34\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 43 36 L 63 41\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 42 40 L 51 49 L 53 52\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 32 32 L 27 33 L 27 34 L 27 35 L 32 36 L 34 35 L 34 33 L 29 32\" stroke=\"black\" fill=\"none\"/>\n",
       "<path d=\"M 26 24 L 26 28\" stroke=\"black\" fill=\"none\"/>\n",
       "</g></svg></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(device)\n",
    "model = model.to(device)\n",
    "\n",
    "svg_inline = \"\"\n",
    "clean_seq = dataset[0].unsqueeze(0).to(device)  # (1, seq_len)\n",
    "\n",
    "for _ in range(5):\n",
    "    noisy_seq = corrupt_input(clean_seq, tokenizer, mask_prob=0.15, dropout_prob=0.05)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(noisy_seq)\n",
    "        preds = torch.argmax(logits, dim=-1)  # (1, seq_len)\n",
    "\n",
    "    denoised_seq = preds.squeeze(0).cpu().tolist()\n",
    "    denoised_svg = tokenizer.decode(denoised_seq)\n",
    "    svg_inline += f'<div style=\"display:inline-block; width: 150px; background-color: white; margin-right:10px;\"><b>Generated</b><br>{denoised_svg}</div>'\n",
    "\n",
    "display(HTML(svg_inline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cfa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a model with latent space and a model to sample from it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
